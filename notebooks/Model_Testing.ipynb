{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test various models for performance on a six-month sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine all of the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the locations of the files for X_train, X_test, and y_train. Also, there is a file that contains information about the individual stations that can be useful for models that learn for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_dir = 'solar/data/kaggle_solar/train/'\n",
    "Xtest_dir = 'solar/data/kaggle_solar/test/'\n",
    "ytrain_file = 'solar/data/kaggle_solar/train.csv'\n",
    "station_file = 'solar/data/kaggle_solar/station_info.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the various files. This is mostly done so that any file updates during testing are carried over to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import solar.wrangle.wrangle\n",
    "import solar.wrangle.subset\n",
    "import solar.wrangle.engineer\n",
    "import solar.analyze.model\n",
    "import solar.report.submission\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all of the variables but only over six months to reduce processing time. The test data is not important for this because nothing will be submitted.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose up to 98 stations; not specifying a station means to use all that fall within the given lats and longs. If the\n",
    "# parameter 'all' is given, then it will use all stations no matter the provided lats and longs\n",
    "station = ['all']\n",
    "#station = ['ACME', 'BEAV']\n",
    "# Determine which dates will be used to train the model. No specified date means use the entire set from 1994-01-01 \n",
    "# until 2007-12-31.\n",
    "#train_dates = ['1994-01-01','2007-12-31']\n",
    "train_dates = ['2000-01-01','2000-07-30']\n",
    "# Determine the test X values to produce. There is no practical purpose to use fewer than all of the points other than\n",
    "# for testing. Again, not choosing a date will use 2008-01-01 through 2012-11-30.\n",
    "test_dates = ['2008-01-01', '2012-11-30']\n",
    "\n",
    "\n",
    "# The last parameter that is not specifically involved in feature selection in the layout to be used for training\n",
    "# I have switched to almost always training for each individual station rather than having a single row for a date.\n",
    "# However, I am still not beating the benchmark, and the file would grow too large to have the benchmark laid out\n",
    "# with a row for each station, so I'll keep the switch. True means that each station has a row (5113 dates X 98\n",
    "# stations to train the data). False means that there are 5113 rows that are being used to train the data.\n",
    "station_layout = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, just duplicate the functionality of the basic grid analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use all variables\n",
    "var = ['uswrf_sfc', 'dswrf_sfc']\n",
    "#var = ['all']\n",
    "\n",
    "# Keep model 0 (the default model) as a column for each of the variables (aggregated over other dimensions)\n",
    "#model = [0, 7]\n",
    "model=[0]\n",
    "# Aggregate over all times\n",
    "#times = ['all']\n",
    "times = [21]\n",
    "default_grid = {'type':'relative', 'axes':{'var':var, 'models':model, 'times':times,\n",
    "                                          'station':station}}\n",
    "just_grid = [default_grid]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This just uses the station_names as another feature\n",
    "stat_names = {'type':'station_names'}\n",
    "stat_feats = [stat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frac_dist = {'type':'frac_dist'}\n",
    "dist_feats = [frac_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days_solstice = {'type':'days_from_solstice'}\n",
    "days_cold = {'type':'days_from_coldest'}\n",
    "days_feats = [days_solstice, days_cold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feats = [frac_dist, days_cold, days_solstice, default_grid, stat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:solar.wrangle.wrangle:Started building test and training data\n",
      "INFO:solar.wrangle.wrangle:Features: [{'type': 'frac_dist'}, {'type': 'days_from_coldest'}, {'type': 'days_from_solstice'}, {'axes': {'var': ['uswrf_sfc', 'dswrf_sfc'], 'models': [0], 'station': ['all'], 'times': [21]}, 'type': 'relative'}, {'type': 'station_names'}]\n",
      "INFO:solar.wrangle.wrangle:Train dates: ['2000-01-01', '2000-07-30']\n",
      "INFO:solar.wrangle.wrangle:Test dates: ['2008-01-01', '2012-11-30']\n",
      "INFO:solar.wrangle.wrangle:Stations: ['all']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar/data/kaggle_solar/train/\n",
      "Here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:solar.wrangle.wrangle:Finished building test and training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "solar/data/kaggle_solar/test/\n",
      " "
     ]
    }
   ],
   "source": [
    "# if I am modifying code for any of these pythons\n",
    "reload(solar.wrangle.wrangle)\n",
    "reload(solar.wrangle.subset)\n",
    "reload(solar.wrangle.engineer)\n",
    "from solar.wrangle.wrangle import SolarData\n",
    "\n",
    "%prun all_feats_data = SolarData.load(Xtrain_dir, ytrain_file, Xtest_dir, station_file, \\\n",
    "                                  train_dates, test_dates, station, \\\n",
    "                                  station_layout, all_feats, 'local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feats_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-21-09-27-29.p', LinearRegression, {'fit_intercept': [True, False]}, cv_splits, \\\n",
    "                    error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-21-09-27-29.p', LinearRegression, {'fit_intercept': [True, False]}, cv_splits, \\\n",
    "                    error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', Ridge, {'alpha':np.logspace(0,2,10,base=10)}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 4\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-21-09-27-29.p', Ridge, {'alpha':np.logspace(-3,1,10,base=10)}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feats_data[0].iloc[0:10,[7, 307]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-20-13-12-51.p', Lasso, {'alpha':np.logspace(-2,2,10,base=10)}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True, random_state=1, selection='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-20-13-12-51.p', Lars, {'n_nonzero_coefs': range(1,11)}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-20-13-12-51.p', LassoLars, {'alpha':np.logspace(3,4,10,base=10)}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', OrthogonalMatchingPursuit, {'n_nonzero_coefs':[int(x) for x in np.logspace(0,2,10,base=10)]}, cv_splits, \\\n",
    "                    error_formula, njobs, write, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', BayesianRidge, {'alpha_1': np.logspace(-8,-4,5), \\\n",
    "                                                                                 'alpha_2': np.logspace(-6,-7,1), \\\n",
    "                                                                                 'lambda_1': np.logspace(-6,-7,1), \\\n",
    "                                                                                 'lambda_2': np.logspace(-6,-7,1)}, \\\n",
    "                                      cv_splits, error_formula, njobs, write, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', ARDRegression, {'alpha_1': np.logspace(-8,-4,5), \\\n",
    "                                                                                 'alpha_2': np.logspace(-6,-7,1), \\\n",
    "                                                                                 'lambda_1': np.logspace(-6,-7,1), \\\n",
    "                                                                                 'lambda_2': np.logspace(-6,-7,1)}, \\\n",
    "                                      cv_splits, error_formula, njobs, write, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pickle.load(open('solar/data/kaggle_solar/inputs/input_2016-02-15-10-30-00.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = KernelRidge(kernel='rbf')\n",
    "%prun model.fit(test_data[0],test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 3\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "#%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', KernelRidge, { \\\n",
    "#        'kernel': ['linear', 'RBF', 'laplacian', 'polynomial', 'exponential', 'chi2', 'sigmoid']}, \\\n",
    "#                                      cv_splits, error_formula, njobs, write)\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', KernelRidge, { \\\n",
    "        'kernel': ['rbf']}, \\\n",
    "                                      cv_splits, error_formula, njobs, write, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "%prun model.fit(test_data[0],test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 3\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', SVR, {'verbose': [True]}, \\\n",
    "                                      cv_splits, error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "model = NuSVR()\n",
    "%prun model.fit(test_data[0],test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 3\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', NuSVR, {'verbose': [True]}, \\\n",
    "                                      cv_splits, error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "%prun model.fit(test_data[0],test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "cv_splits = 10\n",
    "njobs = 1\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', DecisionTreeRegressor, {'splitter': ['best', 'random'], 'max_features': ['auto', 'sqrt', 'log2']}, \\\n",
    "                                      cv_splits, error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "%prun model.fit(test_data[0],np.ravel(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "cv_splits = 3\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "njobs = 3\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-20-13-12-51.p', RandomForestRegressor, \\\n",
    "                                      {'n_estimators':range(1,31,5)}, \\\n",
    "                                      cv_splits, error_formula, njobs, write,\\\n",
    "                                      random_state=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor()\n",
    "%prun model.fit(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import metrics\n",
    "cv_splits = 3\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "njobs = 3\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', ExtraTreesRegressor, \\\n",
    "                                      {'n_estimators':[50]}, \\\n",
    "                                      cv_splits, error_formula, njobs, write,\\\n",
    "                                      random_state=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "%prun model.fit(test_data[0], np.ravel(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import metrics\n",
    "cv_splits = 3\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "njobs = 4\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', AdaBoostRegressor, \\\n",
    "                                      {'n_estimators':[int(x) for x in np.logspace(0,2.6,5)]}, \\\n",
    "                                      cv_splits, error_formula, njobs, write,\\\n",
    "                                      random_state=0, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(verbose=10, learning_rate=0.1)\n",
    "%prun model.fit(test_data[0],np.ravel(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "cv_splits = 3\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "njobs = 4\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-20-13-12-51.p', GradientBoostingRegressor, \\\n",
    "                                      {'n_estimators':[int(x) for x in np.logspace(0,2.6,5)]}, \\\n",
    "                                      cv_splits, error_formula, njobs, write, \\\n",
    "                                      random_state=0, learning_rate=.1, verbose=10, loss='lad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=10, weights='uniform')\n",
    "%prun model.fit(test_data[0],np.ravel(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(solar.analyze.model)\n",
    "import numpy as np\n",
    "from solar.analyze.model import Model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "cv_splits = 3\n",
    "\n",
    "error_formula = 'mean_absolute_error'\n",
    "njobs = 4\n",
    "write = 'local'\n",
    "%prun model = Model.model_from_pickle('input_2016-02-15-10-30-00.p', KNeighborsRegressor, \\\n",
    "                                      {'n_neighbors':[int(x) for x in np.logspace(0,3,10)], 'weights': ['uniform', 'distance']}, \\\n",
    "                                      cv_splits, error_formula, njobs, write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_import_model = pickle.load(open('solar/data/kaggle_solar/models/model_2016-02-18-12-26-18.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_import_model.best_estimator_.train_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
